# -*- coding: utf-8 -*-
"""Final_Exam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YlFipcFpA_Yozi-Eo5gqOMIuY6Pu7R9h

Import Part
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report

import gradio as gr
import pickle

import warnings
warnings.filterwarnings("ignore")

"""# **1. Data Loading (5 Marks)**"""

df = pd. read_csv("/content/diabetes.csv")
df.head(10)

len(df.columns)

len(df)

df.shape

"""# **2. Data Preprocessing (10 Marks)**

## Step 1: Check missing values
"""

df.isnull().sum()

"""## Step 2: Handle zero values"""

cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
df[cols_with_zero] = df[cols_with_zero].replace(0, df[cols_with_zero].median())

df

"""## Step 3: Feature / Target split"""

X = df.drop("Outcome", axis=1)
y = df["Outcome"]

X

# Outlier detection was performed using the Interquartile Range (IQR) method.
# Although some features such as Insulin and Glucose showed high variability, these values represent valid medical measurements rather than noise or data entry errors.
# Therefore, no samples were removed to preserve clinical relevance and avoid loss of important information.

# Outlier check (IQR method - analysis only)
Q1 = X.quantile(0.25)
Q3 = X.quantile(0.75)
IQR = Q3 - Q1
IQR

y

"""## Step 4: Train-test split"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_test

# Preprocessing pipeline
preprocess = Pipeline([
    ("scaler", StandardScaler())
])

"""## Step 5: Feature Scaling"""

scaler = StandardScaler()

"""# 3. Pipeline Creation (10 Marks)"""

pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("model", LogisticRegression(max_iter=1000))
])

"""# 4. Primary Model Selection (5 Marks)

Logistic Regression was selected as the primary model because the dataset represents a binary classification problem. It is computationally efficient, interpretable, and provides a strong baseline for comparison with more complex models.

# 5. Model Training (10 Marks)
"""

# pipeline.fit(X_train, y_train)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, class_weight="balanced"),
    "Decision Tree": DecisionTreeClassifier(class_weight="balanced"),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(),
    "SVM": SVC(probability=True, class_weight="balanced"),
    "KNN": KNeighborsClassifier()
}

"""# Cross-Validation (10 Marks)"""

# cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)
# cv_rmse = np.sqrt(cv_scores)

# print(cv_rmse)

results = {}

for name, model in models.items():
    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("model", model)
    ])

    acc = cross_val_score(pipe, X_train, y_train, cv=5, scoring="accuracy")
    f1 = cross_val_score(pipe, X_train, y_train, cv=5, scoring="f1")

    results[name] = {
        "Mean Accuracy": acc.mean(),
        "Mean F1": f1.mean(),
        "Std": acc.std()
    }

results_df = pd.DataFrame(results).T
results_df = results_df.sort_values("Mean Accuracy", ascending=False)

print("\n===== MODEL COMPARISON =====")
print(results_df)

# print(cv_scores.mean())

# print(cv_scores.std())

best_model_name = results_df.index[0]
print(f"\nBest Model Selected: {best_model_name}")

"""# 7. Hyperparameter Tuning (10 Marks)"""

# param_grid = {
#     "model__C": [0.01, 0.1, 1, 10],
#     "model__solver": ["liblinear", "lbfgs"]
# }

# grid = GridSearchCV(
#     pipeline,
#     param_grid,
#     cv=5,
#     scoring="accuracy"
# )

# grid.fit(X_train, y_train)

# grid.best_params_, grid.best_score_



if best_model_name == "Random Forest":
    param_grid = {
        "model__n_estimators": [100, 200, 300],
        "model__max_depth": [None, 5, 10]
    }

    pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("model", RandomForestClassifier(random_state=42))
    ])

elif best_model_name == "SVM":
    param_grid = {
        "model__C": [0.1, 1, 10],
        "model__kernel": ["rbf", "linear"]
    }

    pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("model", SVC(probability=True))
    ])

else:
    pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("model", models[best_model_name])
    ])
    pipeline.fit(X_train, y_train)
    best_model = pipeline


if best_model_name in ["Random Forest", "SVM"]:
    grid = GridSearchCV(
        pipeline,
        param_grid,
        cv=5,
        scoring="accuracy",
        n_jobs=-1
    )
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    print("\nBest Params:", grid.best_params_)
    print("Best CV Score:", grid.best_score_)

"""# 8. Best Model Selection (10 Marks)"""

# best_model = grid.best_estimator_

best_model_name = results_df.index[0]
print(f"\nBest Model Selected: {best_model_name}")

"""# 9. Model Performance Evaluation (10 Marks)"""

y_pred = best_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""# 10. Web Interface with Gradio (10 Marks)"""

import gradio as gr
import numpy as np

def predict_diabetes(preg, glucose, bp, skin, insulin, bmi, dpf, age):
    data = np.array([[preg, glucose, bp, skin, insulin, bmi, dpf, age]])
    prediction = best_model.predict(data)[0]
    return "Diabetic" if prediction == 1 else "Non-Diabetic"

interface = gr.Interface(
    fn=predict_diabetes,
    inputs=[
        gr.Number(label="Pregnancies"),
        gr.Number(label="Glucose"),
        gr.Number(label="Blood Pressure"),
        gr.Number(label="Skin Thickness"),
        gr.Number(label="Insulin"),
        gr.Number(label="BMI"),
        gr.Number(label="Diabetes Pedigree Function"),
        gr.Number(label="Age"),
    ],
    outputs="text",
    title="Diabetes Prediction System",
    description="Enter patient details to predict diabetes"
)

interface.launch()

"""## Save the Model"""

filename = "final_exam_model.pkl"

with open( filename, "wb" ) as file:
  pickle.dump( best_model, file )